{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T09:45:26.181684Z",
     "start_time": "2021-01-08T09:45:24.300238Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据接口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM Python 模块能够使用以下几种方式来加载数据:\n",
    "+ libsvm/tsv/csv txt format file（libsvm/tsv/csv 文本文件格式）\n",
    "+ Numpy 2D array, pandas object（Numpy 2维数组, pandas 对象）\n",
    "+ LightGBM binary file（LightGBM 二进制文件）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 加载文件\n",
    "train_data = lgb.Dataset('train.svm.bin')\n",
    "# 加载numpy 数组到 Dataset 中\n",
    "data = np.random.rand(500, 10)  # 500 个样本, 每一个包含 10 个特征\n",
    "label = np.random.randint(2, size=500)  # 二元目标变量,  0 和 1\n",
    "train_data = lgb.Dataset(data, label=label)\n",
    "#加载 scpiy.sparse.csr_matrix 数组到 Dataset 中\n",
    "csr = scipy.sparse.csr_matrix((dat, (row, col)))\n",
    "train_data = lgb.Dataset(csr)\n",
    "#保存 Dataset 到 LightGBM 二进制文件将会使得加载更快速\n",
    "train_data = lgb.Dataset('train.svm.txt')\n",
    "train_data.save_binary('train.bin')\n",
    "\n",
    "# 创建验证数据\n",
    "1）test_data = train_data.create_valid('test.svm')\n",
    "2）test_data = lgb.Dataset('test.svm', reference=train_data)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 将参数写成字典形式\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression', # 目标函数     ####regression默认regression_l2\n",
    "    'metric': {'l2', 'auc'},  # 评估函数\n",
    "    'max_depth': 6     ###   树的深度           ###按层\n",
    "    'num_leaves': 50  ###   由于leaves_wise生长，小于2^max_depth   #####按leaf_wise\n",
    "    'learning_rate': 0.05,  # 学习速率\n",
    "    'subsample'/'bagging_fraction':0.8           ###  数据采样\n",
    "    'colsample_bytree'/'feature_fraction': 0.8  ###  特征采样\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'verbose': 1 # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数详解\n",
    "https://lightgbm.readthedocs.io/en/latest/Python-API.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参：https://www.imooc.com/article/43784?block_id=tuijian_wz\n",
    "\n",
    "LightGBM的调参过程和RF、GBDT等类似，其基本流程如下：\n",
    "+ 首先选择较高的学习率，大概0.1附近，这样是为了加快收敛的速度。这对于调参是很有必要的。\n",
    "+ 对决策树基本参数调参：\n",
    "   - 1）max_depth和num_leaves\n",
    "   - 2）min_data_in_leaf和min_sum_hessian_in_leaf\n",
    "   - 3）feature_fraction和bagging_fraction\n",
    "+ 正则化参数调参\n",
    "+ 最后降低学习率，这里是为了最后提高准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原生接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:00:56.641053Z",
     "start_time": "2021-01-08T10:00:56.541318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91\n",
      "[LightGBM] [Info] Number of data points in the train set: 120, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 1.025000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's l2: 0.702763\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's l2: 0.640034\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's l2: 0.583441\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's l2: 0.532384\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's l2: 0.486322\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's l2: 0.442878\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's l2: 0.702763\n",
      "The rmse of prediction is: 0.8383097266846946\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    " \n",
    "# 创建成lgb特征的数据集格式\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    " \n",
    "# 将参数写成字典下形式\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression',  # 目标函数\n",
    "    'metric': {'l2', 'auc'},  # 评估函数\n",
    "    'num_leaves': 31,  # 叶子节点数\n",
    "    'learning_rate': 0.05,  # 学习速率\n",
    "    'feature_fraction': 0.9,  # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8,  # 建树的样本采样比例\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'verbose': 1  # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}\n",
    " \n",
    "# 训练 cv and train\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=20, valid_sets=lgb_eval, early_stopping_rounds=5)\n",
    " \n",
    "# 保存模型到文件\n",
    "gbm.save_model('model.txt')\n",
    " \n",
    "# 预测数据集\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    " \n",
    "# 评估模型\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn接口实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:17:23.862088Z",
     "start_time": "2021-01-08T10:17:23.710492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.591321\tvalid_0's l2: 0.561313\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l1: 0.568299\tvalid_0's l2: 0.517453\n",
      "[3]\tvalid_0's l1: 0.546427\tvalid_0's l2: 0.477944\n",
      "[4]\tvalid_0's l1: 0.525649\tvalid_0's l2: 0.442359\n",
      "[5]\tvalid_0's l1: 0.505911\tvalid_0's l2: 0.410312\n",
      "[6]\tvalid_0's l1: 0.487158\tvalid_0's l2: 0.381454\n",
      "[7]\tvalid_0's l1: 0.469344\tvalid_0's l2: 0.355471\n",
      "[8]\tvalid_0's l1: 0.45242\tvalid_0's l2: 0.33208\n",
      "[9]\tvalid_0's l1: 0.436343\tvalid_0's l2: 0.311025\n",
      "[10]\tvalid_0's l1: 0.422146\tvalid_0's l2: 0.293244\n",
      "[11]\tvalid_0's l1: 0.408659\tvalid_0's l2: 0.277265\n",
      "[12]\tvalid_0's l1: 0.39485\tvalid_0's l2: 0.261816\n",
      "[13]\tvalid_0's l1: 0.37997\tvalid_0's l2: 0.243512\n",
      "[14]\tvalid_0's l1: 0.368479\tvalid_0's l2: 0.231915\n",
      "[15]\tvalid_0's l1: 0.355278\tvalid_0's l2: 0.216033\n",
      "[16]\tvalid_0's l1: 0.345354\tvalid_0's l2: 0.206682\n",
      "[17]\tvalid_0's l1: 0.334284\tvalid_0's l2: 0.193469\n",
      "[18]\tvalid_0's l1: 0.325227\tvalid_0's l2: 0.185919\n",
      "[19]\tvalid_0's l1: 0.315843\tvalid_0's l2: 0.175524\n",
      "[20]\tvalid_0's l1: 0.30761\tvalid_0's l2: 0.168686\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.30761\tvalid_0's l2: 0.168686\n",
      "The rmse of prediction is: 0.41071454668729646\n",
      "Feature importances: [0, 4, 33, 25]\n",
      "Best parameters found by grid search are: {'learning_rate': 0.1, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# 加载数据\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    " \n",
    "# 创建模型，训练模型\n",
    "gbm = lgb.LGBMRegressor(objective='regression', num_leaves=31, learning_rate=0.05, n_estimators=20)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='l1', early_stopping_rounds=5)\n",
    " \n",
    "# 测试机预测\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    " \n",
    "# 模型评估\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    " \n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importances_))\n",
    " \n",
    "# 网格搜索，参数优化\n",
    "estimator = lgb.LGBMRegressor(num_leaves=31)\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [20, 40]\n",
    "}\n",
    "gbm = GridSearchCV(estimator, param_grid)\n",
    "gbm.fit(X_train, y_train)\n",
    "print('Best parameters found by grid search are:', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原生API与sklearnAPI接口区别总结\n",
    "1.多分类时lgb.train除了’objective’:‘multiclass’,还要指定\"num_class\":5，而sklearn接口只需要指定’objective’:‘multiclass’。\n",
    "\n",
    "2.lgb.train中正则化参数为\"lambda_l1\", “lambda_l1”，sklearn中则为’reg_alpha’, ‘reg_lambda’。\n",
    "\n",
    "3.迭代次数在sklearn中是’n_estimators’:300，在初始化模型时指定。而在lgb.train中则可在参数params中指定，也可在函数形参中指出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
